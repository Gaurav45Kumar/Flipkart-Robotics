import cv2
import pytesseract
import numpy as np
import tensorflow as tf

# Initialize the camera (0 for the default camera)
cap = cv2.VideoCapture(0)

# Load the pre-trained MobileNet SSD model for object detection
model = tf.saved_model.load('ssd_mobilenet_v2_fpnlite_320x320/saved_model')
detect_fn = model.signatures['serving_default']

# Function to extract text using OCR
def extract_text(image):
    # Convert the image to grayscale for better OCR results
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Use Tesseract to extract text
    text = pytesseract.image_to_string(gray)
    return text

# Function for object detection
def detect_objects(image):
    # Convert image to a tensor for TensorFlow detection model
    input_tensor = tf.convert_to_tensor([image])
    detections = detect_fn(input_tensor)

    # Extract detection data: boxes, classes, and scores
    detection_boxes = detections['detection_boxes'][0].numpy()
    detection_scores = detections['detection_scores'][0].numpy()
    detection_classes = detections['detection_classes'][0].numpy()

    # Filter detections with confidence > 0.5
    valid_detections = [(detection_boxes[i], detection_classes[i], detection_scores[i])
                        for i in range(len(detection_scores)) if detection_scores[i] > 0.5]

    return valid_detections

# Main loop for image capture and processing
while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    # If frame is read correctly, proceed
    if not ret:
        print("Failed to grab frame")
        break

    # Display the captured frame for debugging
    cv2.imshow("Camera Feed", frame)

    # Extract text (like expiry date or MRP) using OCR
    text = extract_text(frame)
    print(f"Extracted Text: {text}")

    # Perform object detection
    detections = detect_objects(frame)
    
    # Draw detection results on the frame
    for box, cls, score in detections:
        ymin, xmin, ymax, xmax = box
        start_point = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))
        end_point = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))
        color = (0, 255, 0)  # Green bounding box
        frame = cv2.rectangle(frame, start_point, end_point, color, 2)

        # Display class and score on the detection box
        label = f"Class: {int(cls)}, Score: {score:.2f}"
        cv2.putText(frame, label, (start_point[0], start_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Show the result with detected objects
    cv2.imshow("Detection Results", frame)

    # Press 'q' to quit the video stream
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the camera and close all windows
cap.release()
cv2.destroyAllWindows()
